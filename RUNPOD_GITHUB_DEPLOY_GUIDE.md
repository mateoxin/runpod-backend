# ğŸš€ **PEÅNA INSTRUKCJA DEPLOY BACKEND Z GITHUB NA RUNPOD**

## ğŸ“‹ **KROK ZA KROKIEM - RUNPOD SERVERLESS ENDPOINT**

### **1ï¸âƒ£ PRZYGOTOWANIE GITHUB REPOSITORY**

âœ… **Repository juÅ¼ gotowe**: `https://github.com/mateoxin/runpod-backend.git`
âœ… **Branch**: `main`
âœ… **Kod zaktualizowany**: HF token ze zmiennych Å›rodowiskowych

### **2ï¸âƒ£ LOGOWANIE DO RUNPOD CONSOLE**

1. **IdÅº do**: [https://runpod.io/console](https://runpod.io/console)
2. **Zaloguj siÄ™** do swojego konta RunPod
3. **PrzejdÅº do**: `Serverless` â†’ `My Endpoints`

### **3ï¸âƒ£ TWORZENIE NOWEGO ENDPOINT**

1. **Kliknij**: `+ New Endpoint`
2. **Wybierz**: `Deploy from GitHub`

### **4ï¸âƒ£ KONFIGURACJA GITHUB REPOSITORY**

```yaml
Repository Settings:
  Repository URL: https://github.com/mateoxin/runpod-backend.git
  Branch: main
  Docker Context: /
  Dockerfile Path: Dockerfile
```

### **5ï¸âƒ£ KONFIGURACJA ÅšRODOWISKA (ENVIRONMENT VARIABLES)**

âš ï¸ **TYLKO JEDNA ZMIENNA DO USTAWIENIA**:

```bash
# ğŸ”‘ JEDYNA WYMAGANA ZMIENNA
HF_TOKEN=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
```

âœ… **AUTOMATYCZNIE USTAWIONE W DOCKERFILE** (nie musisz ich dodawaÄ‡):
```bash
# âœ… JuÅ¼ skonfigurowane automatycznie:
WORKSPACE_PATH=/workspace
PYTHONUNBUFFERED=1
HOST=0.0.0.0
PORT=8000
DEBUG=false
MOCK_MODE=false
MAX_CONCURRENT_JOBS=10
GPU_TIMEOUT=14400
```

ğŸ¯ **OPCJONALNE** (tylko jeÅ›li chcesz zmieniÄ‡ domyÅ›lne):
```bash
# MoÅ¼esz nadpisaÄ‡ w RunPod Console jeÅ›li potrzebujesz:
REDIS_URL=redis://your-redis:6379/0  # domyÅ›lnie: redis://localhost:6379/0
MAX_CONCURRENT_JOBS=20               # domyÅ›lnie: 10
GPU_TIMEOUT=7200                     # domyÅ›lnie: 14400 (4h)
```

### **6ï¸âƒ£ KONFIGURACJA GPU**

```yaml
GPU Configuration:
  GPU Type: NVIDIA A40 (24GB VRAM) - ZALECANE
  Alternative: RTX A6000, A100
  Min VRAM: 16GB dla FLUX.1-dev
  
Scaling:
  Min Workers: 0 (scale to zero)
  Max Workers: 10
  Scale Down Delay: 5 minutes
  Worker Timeout: 15 minutes
```

### **7ï¸âƒ£ KONFIGURACJA DOCKER**

```yaml
Docker Settings:
  Container Start Command: python -u /app/app/rp_handler.py
  Container Registry: (leave empty for GitHub)
  Container Disk: 50GB (recommended)
```

### **8ï¸âƒ£ DEPLOY I MONITORING**

1. **Kliknij**: `Deploy`
2. **Monitoruj logi** - oczekiwany output:

```
ğŸš€ Setting up environment at runtime...
ğŸ“¦ Installing Redis and AWS dependencies...
âœ… Redis and AWS dependencies installed successfully
ğŸ“ Creating workspace directories...
ğŸ¤— Setting up HuggingFace token...
âœ… HuggingFace token configured
ğŸ¤– Installing AI-Toolkit (ostris/ai-toolkit)...
ğŸ“¥ Cloning AI-Toolkit repository...
âœ… AI-Toolkit repository cloned successfully
ğŸ“¦ Installing AI-Toolkit dependencies...
âœ… AI-Toolkit dependencies installed successfully
âœ… Environment setup completed successfully!
```

**â±ï¸ Czas startup**: 3-5 minut (pierwsze uruchomienie)

### **9ï¸âƒ£ TESTOWANIE ENDPOINT**

Po udanym deploy otrzymasz **Endpoint URL**:
```
https://api.runpod.ai/v2/YOUR_ENDPOINT_ID
```

#### **Test Health Check:**
```bash
curl -X POST https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/runsync \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_RUNPOD_API_TOKEN" \
  -d '{
    "input": {
      "type": "health_check"
    }
  }'
```

#### **Oczekiwany Response:**
```json
{
  "id": "unique-request-id",
  "status": "COMPLETED",
  "output": {
    "status": "healthy",
    "environment_ready": true,
    "hf_token_configured": true,
    "ai_toolkit_available": true,
    "uptime": "00:05:23"
  }
}
```

---

## ğŸ”§ **ADVANCED CONFIGURATION**

### **ğŸŒ Environment Variables - PeÅ‚na Lista**

| Variable | Required | Auto-Set | Default | Description |
|----------|----------|----------|---------|-------------|
| `HF_TOKEN` | âœ… **YES** | âŒ | - | HuggingFace token (USTAW RÄ˜CZNIE) |
| `WORKSPACE_PATH` | No | âœ… | `/workspace` | Main workspace path |
| `PYTHONUNBUFFERED` | No | âœ… | `1` | Python logging |
| `HOST` | No | âœ… | `0.0.0.0` | Server host |
| `PORT` | No | âœ… | `8000` | Server port |
| `DEBUG` | No | âœ… | `false` | Debug mode |
| `MOCK_MODE` | No | âœ… | `false` | Mock mode for testing |
| `MAX_CONCURRENT_JOBS` | No | âœ… | `10` | Max parallel jobs |
| `GPU_TIMEOUT` | No | âœ… | `14400` | GPU timeout (seconds) |
| `REDIS_URL` | No | âŒ | `redis://localhost:6379/0` | Redis connection |

### **ğŸ“Š Performance Optimization**

#### **GPU Selection Guide:**
- **NVIDIA A40** (24GB): Najlepszy stosunek cena/wydajnoÅ›Ä‡
- **RTX A6000** (48GB): Dla duÅ¼ych modeli
- **A100** (40GB/80GB): Najszybszy, ale droÅ¼szy

#### **Cost Optimization:**
- **Scale to Zero**: Automatyczne po 5 minutach bezczynnoÅ›ci
- **Shared Storage**: UÅ¼yj RunPod Network Storage dla modeli
- **Model Caching**: Modele cachowane miÄ™dzy uruchomieniami

### **ğŸ” Monitoring i Debugging**

#### **Logi do monitorowania:**
```
âœ… Environment setup completed successfully!
ğŸ”„ Handler started successfully
ğŸ“¡ Server listening on 0.0.0.0:8000
```

#### **BÅ‚Ä™dy do obserwacji:**
```
âŒ HF token login failed
âŒ AI-Toolkit clone failed  
âŒ GPU allocation failed
```

---

## ğŸš¨ **TROUBLESHOOTING**

### **Problem 1: "Environment Setup Failed"**
**Przyczyna**: Brak HF_TOKEN lub bÅ‚Ä™dna wartoÅ›Ä‡
**RozwiÄ…zanie**: 
1. SprawdÅº Environment Variables w RunPod Console
2. Upewnij siÄ™ Å¼e `HF_TOKEN=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`

### **Problem 2: "AI-Toolkit Clone Failed"**
**Przyczyna**: Problemy z sieciÄ… lub brak git
**RozwiÄ…zanie**: 
1. SprawdÅº logi - czy git jest dostÄ™pny
2. MoÅ¼e byÄ‡ timeout - zwiÄ™ksz timeout w kodzie

### **Problem 3: "GPU Not Available"**
**Przyczyna**: Brak dostÄ™pnych GPU w regionie
**RozwiÄ…zanie**:
1. ZmieÅ„ region w RunPod Console
2. Wybierz inny typ GPU (A40 â†’ RTX A6000)
3. Poczekaj na dostÄ™pnoÅ›Ä‡

### **Problem 4: "Slow Startup"**
**Przyczyna**: Pierwsze uruchomienie - instalacja zaleÅ¼noÅ›ci
**RozwiÄ…zanie**: 
- Pierwszy start: 3-5 minut (normalne)
- Kolejne starty: 30-60 sekund (cache)

---

## âœ… **SUPER PROSTY CHECKLIST PRZED DEPLOY**

- [ ] Repository URL: `https://github.com/mateoxin/runpod-backend.git`
- [ ] Branch: `main`
- [ ] Dockerfile Path: `Dockerfile`
- [ ] **JEDYNA RÄ˜CZNA KONFIGURACJA**: HF_TOKEN = `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`
- [ ] GPU Type: A40 lub lepszy
- [ ] Min Workers: 0, Max Workers: 10
- [ ] Container Start Command: `python -u /app/app/rp_handler.py`

ğŸ‰ **POZOSTAÅE ZMIENNE AUTOMATYCZNIE USTAWIONE W DOCKERFILE!**

---

## ğŸ‰ **PO UDANYM DEPLOY**

### **DostÄ™pne API Endpoints:**
```
âœ… Health Check: POST /runsync {"input": {"type": "health_check"}}
âœ… LoRA Training: POST /runsync {"input": {"type": "train", "config": {...}}}
âœ… Image Generation: POST /runsync {"input": {"type": "generate", "prompt": "..."}}
âœ… Process Management: GET /health, /api/processes
âœ… File Management: POST /api/upload, GET /api/files
```

### **PrzykÅ‚ad uÅ¼ycia:**
```python
import requests

endpoint_url = "https://api.runpod.ai/v2/YOUR_ENDPOINT_ID"
headers = {
    "Authorization": "Bearer YOUR_RUNPOD_API_TOKEN",
    "Content-Type": "application/json"
}

# Health check
response = requests.post(
    f"{endpoint_url}/runsync",
    headers=headers,
    json={"input": {"type": "health_check"}}
)

print(response.json())
```

---

## ğŸ“ **SUPPORT**

W przypadku problemÃ³w:
1. **SprawdÅº logi** w RunPod Console
2. **Zweryfikuj Environment Variables**
3. **SprawdÅº dostÄ™pnoÅ›Ä‡ GPU** w wybranym regionie
4. **Poczekaj na peÅ‚ny startup** (5 minut)

**ğŸš€ GOTOWE! Backend jest teraz dostÄ™pny na RunPod!**